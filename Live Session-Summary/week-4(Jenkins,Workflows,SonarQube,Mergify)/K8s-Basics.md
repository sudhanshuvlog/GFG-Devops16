## GitHub Actions 

### GitHub Actions - GitHub Token

- GitHub Actions utilizes a token for seamless authentication with GitHub. This token, automatically generated by GitHub, is conveniently accessible through the `GITHUB_TOKEN` environment variable. This token grants workflows the necessary permissions to interact with GitHub features.

**Example:**
```yaml
name: Greetings

on: [pull_request_target, issues]

jobs:
  greeting:
    runs-on: ubuntu-latest
    permissions:
      issues: write
      pull-requests: write
    steps:
    - uses: actions/first-interaction@v1
      with:
        repo-token: ${{ secrets.GITHUB_TOKEN }}
        issue-message: "Hello, Thanks for opening your first Issue. I will review it soon, Thanks"
        pr-message: "Hello, Thanks for opening your first Pull request. I will review it soon, Thanks"
```
- In this above example, we are using the `GITHUB_TOKEN` to interact with the issues and pull requests. This token is automatically created by GitHub and is available to our workflows so that they can leverage this token for seamless integration with GitHub features, streamlining the development and collaboration process.

---

## K8S

Before we start with K8S, Let's understand Monolithic, Microservices architecture and Container Orchestration.

### What is a Monolithic architecture?

- A monolithic architecture is a singular, large computing network with one code base that couples all of the business concerns together.

### What are Microservices?

- Microservices - also known as microservice architecture - is an architectural style that structures an application as a collection of services that are:
    - Independently deployable
    - Loosely coupled
Ref: https://microservices.io/
- **Need for Microservices:**
    - If we deploy a monolithic application, we need to deploy the entire application even if we make a small change in the code.
    - If one part of the application is not working, the entire application will not work.
    - So In this case, We can leverage the Microservices architecture to solve the above problems.

### Container Orchestration

Container orchestration automatically provisions, deploys, scales, and manages containerized applications without worrying about the underlying infrastructure

### What is K8S?

- Kubernetes is an open-source container orchestration platform that automates many of the manual processes involved in deploying, managing, and scaling containerized applications.
- Kubernetes is a portable, extensible, open-source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation.
- **Need for K8S :**
    - If we have a large number of containers, it is difficult to manage them manually.
    - Let's say we have 100 microservices and we need to deploy them in a server.
    - We need to manage the 100 microservices in the server.
    - We need to manage the scaling, load balancing, and other things.
    - So In this case, We can leverage the K8S to solve the above problems.

### K8S Setup

- First, we have to install docker to run the minikube.
```
yum install docker -y
systemctl start docker
```
- Then we have to install minikube. You can use this link to install minikube - https://minikube.sigs.k8s.io/docs/start/
- Once the minikube is installed, we can start the minikube using the below command.
```
minikube start
```

### Why did we install Minikube?

- Generally, K8S comes with a lot of services, So it's a lengthy process to install and manage them.
- So, we can use minikube to learn and develop for Kubernetes.

### Kubectl

- Now, we have to install `kubectl` to communicate with the Kubernetes cluster.
- You can use this link to install kubectl - https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/ and don't forget to make it executable.
- `kubectl` is a program used to communicate with the Kubernetes cluster.
- We can use `kubectl` to deploy applications, inspect and manage cluster resources, and view logs.

### K8s Commands used in the session

- **kubectl run pod_name --image=nginx** - This command is used to run a pod in the Kubernetes cluster.
- **kubectl get pods** - This command is used to get the pods in the Kubernetes cluster.
- **kubectl delete pod pod_name** - This command is used to delete the pod in the Kubernetes cluster.
- **kubectl expose pod pod_name --port=80 --name=nginx-service --type=NodePort** - This command is used to expose the pod in the Kubernetes cluster with NodePort Type.
- **kubectl get svc** - This command is used to get the services in the Kubernetes cluster.
- **kubectl create deployment mydep1 --image=nginx** - This command is used to create a deployment in the Kubernetes cluster.
- **kubectl get deployments** - This command is used to get the deployments in the Kubernetes cluster.
- **kubectl delete deployment mydep1** - This command is used to delete the deployment in the Kubernetes cluster.

### Kubernetes file

- We can use commands to create the pods, deployments, services, etc. But, it's difficult to manage them.
- So, we can use the Kubernetes file to manage them.
- It will be written in the YAML format.
- We can write the configuration in a file and we can use the file to create the pods, deployments, services, etc.
- **Example of Kubernetes file:**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mypod
  labels:
    app: myapp
spec:

  containers:
  - name: mycontainer
    image: nginx
    ports:
    - containerPort: 80
```
- In this above example, we are creating a pod using the Kubernetes file.
